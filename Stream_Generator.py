import json
import os
import re
import subprocess
import sqlite3

# Configuration: paths to NPM files
NPM_DATA_DIR = "./data/nginx-proxy-manager"  # Change this if your volume is different
STREAMS_FILE = os.path.join("data", "nginx", "stream", "streams.json")
PROXY_HOSTS_FILE = os.path.join("data", "nginx-proxy-manager", "proxy_hosts.json")
PORTS_FILE = "ports.txt"  # File with the list of ports/ranges generated by the other script
WS_PORTS_FILE = "ws_ports.json"

# Change the paths to read the real .conf files from Nginx Proxy Manager
NGINX_STREAM_DIR = os.path.join("data", "nginx", "stream")
NGINX_PROXY_HOST_DIR = os.path.join("data", "nginx", "proxy_host")
SQLITE_DB_PATH = os.path.join("data", "database.sqlite")

def expand_ports(line):
    """Converts a line like '80,443,1000:1005' into a list of integers."""
    ports = set()
    # Replace line breaks with commas and remove extra spaces
    parts = re.split(r'[,\n]+', line)
    for part in parts:
        part = part.strip()
        if not part:
            continue
        if ':' in part:
            ini, fin = part.split(':')
            ports.update(range(int(ini), int(fin) + 1))
        else:
            ports.add(int(part))
    return ports

def load_ports(path):
    with open(path, 'r') as f:
        content = f.read()
    return expand_ports(content)

def load_existing_streams(path):
    if not os.path.exists(path):
        return set()
    with open(path, 'r') as f:
        data = json.load(f)
    # Consider port and protocol to avoid duplicates
    ports = set()
    for entry in data:
        port = entry.get("port")
        proto = entry.get("protocol", "tcp")
        if port and proto:
            ports.add((int(port), proto.lower()))
    return ports

def load_existing_proxy_hosts(path):
    if not os.path.exists(path):
        return set()
    with open(path, 'r') as f:
        data = json.load(f)
    ports = set()
    for entry in data:
        forward_port = entry.get("forward_port")
        if forward_port:
            ports.add(int(forward_port))
    return ports

def ports_in_streams_conf():
    """Reads all .conf stream files and returns a set of (port, protocol) present."""
    existing = set()
    if not os.path.isdir(NGINX_STREAM_DIR):
        return existing
    for fname in os.listdir(NGINX_STREAM_DIR):
        if not fname.endswith('.conf'):
            continue
        with open(os.path.join(NGINX_STREAM_DIR, fname), 'r') as f:
            content = f.read()
            # Find lines 'listen <port>;' and 'listen <port> udp;'
            for match in re.finditer(r'listen\s+(\d+)(?:\s+udp)?;', content):
                port = int(match.group(1))
                if 'udp' in match.group(0):
                    existing.add((port, 'udp'))
                else:
                    existing.add((port, 'tcp'))
    return existing

def ports_in_proxy_host_conf():
    """Reads all .conf proxy_host files and returns a set of present ports."""
    existing = set()
    if not os.path.isdir(NGINX_PROXY_HOST_DIR):
        return existing
    for fname in os.listdir(NGINX_PROXY_HOST_DIR):
        if not fname.endswith('.conf'):
            continue
        with open(os.path.join(NGINX_PROXY_HOST_DIR, fname), 'r') as f:
            content = f.read()
            # Find lines 'listen <port>;'
            for match in re.finditer(r'listen\s+(\d+);', content):
                existing.add(int(match.group(1)))
    return existing

def generate_stream_conf(port, proto, forward_ip="127.0.0.1", forward_port=None):
    """Generates the content of a stream .conf file for NPM."""
    if forward_port is None:
        forward_port = port
    proto_tag = " udp" if proto == "udp" else ""
    proto_comment = "UDP: true" if proto == "udp" else "TCP: true"
    comment_line = f"# {port} {proto_comment}"
    server_block = f"""
server {{
  listen {port}{proto_tag};
  #listen [::]:{port}{proto_tag};

  proxy_pass {forward_ip}:{forward_port};

  # Custom
  include /data/nginx/custom/server_stream[.]conf;
  include /data/nginx/custom/server_stream_{proto}[.]conf;
}}
"""
    return f"# ------------------------------------------------------------\n{comment_line}\n# ------------------------------------------------------------\n{server_block.strip()}\n"

# Ports reserved by NPM by default (add more if your setup uses others)
RESERVED_PORTS = {80, 81, 443, 3306, 6379, 3000, 8080, 8181, 8765}

def ports_in_streams_sqlite():
    """Reads the NPM SQLite database and returns a set of (port, protocol) present in streams."""
    existing = set()
    if not os.path.exists(SQLITE_DB_PATH):
        return existing
    conn = sqlite3.connect(SQLITE_DB_PATH)
    try:
        cur = conn.cursor()
        cur.execute("SELECT port, protocol FROM streams")
        for port, proto in cur.fetchall():
            existing.add((int(port), proto.lower()))
    except Exception:
        pass
    finally:
        conn.close()
    return existing

def ports_in_proxy_host_sqlite():
    """Reads the NPM SQLite database and returns a set of ports present in proxy_hosts."""
    existing = set()
    if not os.path.exists(SQLITE_DB_PATH):
        return existing
    conn = sqlite3.connect(SQLITE_DB_PATH)
    try:
        cur = conn.cursor()
        cur.execute("SELECT forward_port FROM proxy_host")
        for (port,) in cur.fetchall():
            if port is not None:
                existing.add(int(port))
    except Exception:
        pass
    finally:
        conn.close()
    return existing

def add_streams_sqlite(new_entries):
    """Adds new stream entries to the NPM SQLite database."""
    if not new_entries:
        return
    if not os.path.exists(SQLITE_DB_PATH):
        print("NPM SQLite database not found.")
        return
    conn = sqlite3.connect(SQLITE_DB_PATH)
    try:
        cur = conn.cursor()
        # Check if the 'stream' table exists
        cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='stream';")
        if not cur.fetchone():
            print("The 'stream' table does not exist in the database. Cannot add streams.")
            return
        # Group by port to insert only once per port
        by_port = {}
        for port, proto in new_entries:
            if port not in by_port:
                by_port[port] = {"tcp": 0, "udp": 0}
            by_port[port][proto] = 1
        for port, protos in by_port.items():
            cur.execute(
                "INSERT INTO stream (created_on, modified_on, owner_user_id, is_deleted, incoming_port, forwarding_host, forwarding_port, tcp_forwarding, udp_forwarding, meta, enabled, certificate_id) VALUES (datetime('now'), datetime('now'), 1, 0, ?, ?, ?, ?, ?, ?, 1, 0)",
                (
                    int(port),
                    "127.0.0.1",
                    int(port),
                    protos["tcp"],
                    protos["udp"],
                    '{}',
                )
            )
        conn.commit()
        print(f"{len(by_port)} streams added to the SQLite database.")
    except Exception as e:
        print(f"Error adding streams to the database: {e}")
    finally:
        conn.close()

def read_streams_sqlite():
    """Reads all streams from the database and returns a list of dicts with their data."""
    if not os.path.exists(SQLITE_DB_PATH):
        return []
    conn = sqlite3.connect(SQLITE_DB_PATH)
    conn.row_factory = sqlite3.Row
    try:
        cur = conn.cursor()
        cur.execute("SELECT * FROM stream WHERE is_deleted=0 AND enabled=1")
        return [dict(row) for row in cur.fetchall()]
    finally:
        conn.close()

def generate_stream_conf_from_sqlite(stream):
    """Generates the content of a stream .conf file from a stream table record."""
    port = stream["incoming_port"]
    forwarding_host = stream["forwarding_host"]
    forwarding_port = stream["forwarding_port"]
    tcp = stream.get("tcp_forwarding", 0)
    udp = stream.get("udp_forwarding", 0)
    blocks = []
    if tcp:
        blocks.append(f"""
server {{
  listen {port};
  #listen [::]:{port};

  proxy_pass {forwarding_host}:{forwarding_port};

  # Custom
  include /data/nginx/custom/server_stream[.]conf;
  include /data/nginx/custom/server_stream_tcp[.]conf;
}}
""".strip())
    if udp:
        blocks.append(f"""
server {{
  listen {port} udp;
  #listen [::]:{port} udp;

  proxy_pass {forwarding_host}:{forwarding_port};

  # Custom
  include /data/nginx/custom/server_stream[.]conf;
  include /data/nginx/custom/server_stream_udp[.]conf;
}}
""".strip())
    proto_comment = []
    if tcp:
        proto_comment.append("TCP: true")
    if udp:
        proto_comment.append("UDP: true")
    comment_line = f"# {port} {' '.join(proto_comment)}"
    return f"# ------------------------------------------------------------\n{comment_line}\n# ------------------------------------------------------------\n" + "\n\n".join(blocks) + "\n"

def sync_streams_conf_with_sqlite():
    """Syncs the stream .conf files with the content of the SQLite database."""
    streams = read_streams_sqlite()
    os.makedirs(NGINX_STREAM_DIR, exist_ok=True)
    # Delete all current .conf files
    for fname in os.listdir(NGINX_STREAM_DIR):
        if fname.endswith('.conf'):
            os.remove(os.path.join(NGINX_STREAM_DIR, fname))
    # Generate one .conf per stream (using the id as the filename)
    for stream in streams:
        conf_content = generate_stream_conf_from_sqlite(stream)
        conf_filename = os.path.join(NGINX_STREAM_DIR, f"{stream['id']}.conf")
        with open(conf_filename, "w") as f:
            f.write(conf_content)
        print(f"File synced: {conf_filename}")

def load_ws_ports(path):
    """Carga la lista de pares {ip, puerto} desde ws_ports.json."""
    if not os.path.exists(path):
        return []
    with open(path, "r") as f:
        try:
            data = json.load(f)
        except Exception:
            data = []
    # Devuelve lista de tuplas (ip, puerto)
    return [(entry["ip"], int(entry["puerto"])) for entry in data if "ip" in entry and "puerto" in entry]

def main():
    # 1. Leer los pares (ip, puerto) reportados por los clientes
    ws_ports = load_ws_ports(WS_PORTS_FILE)
    if not ws_ports:
        print("No hay puertos reportados en ws_ports.json. Abortando.")
        return

    # 2. Excluir puertos reservados
    ws_ports = [(ip, port) for ip, port in ws_ports if port not in RESERVED_PORTS]

    # 3. Leer puertos/protocolos existentes en la base de datos
    streams_ports = ports_in_streams_sqlite()
    proxy_ports = ports_in_proxy_host_sqlite()

    # 4. Determinar qué streams faltan (solo para los reportados)
    new_entries = []
    for ip, port in ws_ports:
        tcp_missing = (port, "tcp") not in streams_ports and port not in proxy_ports
        udp_missing = (port, "udp") not in streams_ports and port not in proxy_ports
        # Puedes ajustar si quieres solo tcp, udp o ambos
        if tcp_missing:
            new_entries.append((port, "tcp", ip))
        if udp_missing:
            new_entries.append((port, "udp", ip))

    print(f"{len(new_entries)} nuevos streams serán generados para NPM.")

    # 5. Crear los streams en la base de datos (usando la IP correcta)
    if new_entries:
        os.makedirs(NGINX_STREAM_DIR, exist_ok=True)
        # Insertar en la base de datos
        add_streams_sqlite_with_ip(new_entries)
        # 6. Reiniciar el contenedor
        print("Reiniciando Nginx Proxy Manager con docker-compose...")
        subprocess.run(["docker-compose", "down"], check=True)
        subprocess.run(["docker-compose", "up", "-d"], check=True)
        print("Contenedor reiniciado.")
    else:
        print("No hay nuevos streams para agregar. No se reiniciará el contenedor.")

    # 7. Sincronizar los .conf con la base de datos
    sync_streams_conf_with_sqlite()

def add_streams_sqlite_with_ip(new_entries):
    """Agrega nuevos streams a la base de datos, usando la IP de destino."""
    if not new_entries:
        return
    if not os.path.exists(SQLITE_DB_PATH):
        print("NPM SQLite database not found.")
        return
    conn = sqlite3.connect(SQLITE_DB_PATH)
    try:
        cur = conn.cursor()
        # Verifica si existe la tabla 'stream'
        cur.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='stream';")
        if not cur.fetchone():
            print("La tabla 'stream' no existe en la base de datos. No se pueden agregar streams.")
            return
        # Agrupa por puerto para insertar solo una vez por puerto
        by_port = {}
        for port, proto, ip in new_entries:
            if port not in by_port:
                by_port[port] = {"tcp": 0, "udp": 0, "ip": ip}
            by_port[port][proto] = 1
            by_port[port]["ip"] = ip  # Usa la última IP reportada para ese puerto
        for port, protos in by_port.items():
            cur.execute(
                "INSERT INTO stream (created_on, modified_on, owner_user_id, is_deleted, incoming_port, forwarding_host, forwarding_port, tcp_forwarding, udp_forwarding, meta, enabled, certificate_id) VALUES (datetime('now'), datetime('now'), 1, 0, ?, ?, ?, ?, ?, ?, 1, 0)",
                (
                    int(port),
                    protos["ip"],
                    int(port),
                    protos["tcp"],
                    protos["udp"],
                    '{}',
                )
            )
        conn.commit()
        print(f"{len(by_port)} streams agregados a la base de datos SQLite.")
    except Exception as e:
        print(f"Error agregando streams a la base de datos: {e}")
    finally:
        conn.close()

if __name__ == "__main__":
    if os.environ.get("RUN_FROM_PANEL") != "1":
        print("This script must be run from Control_Panel.py")
        import sys
        sys.exit(1)
    main()
